{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a3d416d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import csv\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "857d1f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory paths\n",
    "dir_paths = [\"Dataset/ECG Images of COVID-19 Patients (250)\", \"Dataset/ECG Images of Myocardial Infarction Patients (77)\", \"Dataset/ECG Images of Patient that have abnormal heart beats (548)\", \"Dataset/ECG Images of Patient that have History of MI (203)\", \"Dataset/Normal Person ECG Images (859)\"]\n",
    "\n",
    "# Create a list to store the image filenames\n",
    "image_filenames = []\n",
    "\n",
    "# Loop through the directories and add the image filenames to the list\n",
    "for dir_path in dir_paths:\n",
    "    for filename in os.listdir(dir_path):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            image_filenames.append(filename)\n",
    "\n",
    "# Create a CSV file and write the image filenames and label \"0\" to it\n",
    "with open(\"image_labels.csv\", mode=\"w\", newline=\"\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"filename\", \"label\"])\n",
    "    for image_filename in image_filenames:\n",
    "        if \"Normal\" in image_filename:\n",
    "            writer.writerow([image_filename, \"0\"])\n",
    "        else:\n",
    "            writer.writerow([image_filename, \"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9bf4dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "# directory containing the images to be cropped\n",
    "input_dir = \"Dataset/ECG Images of COVID-19 Patients (250)/\"\n",
    "\n",
    "# loop through all files in the directory\n",
    "for filename in os.listdir(input_dir):\n",
    "    # check if the file is an image file\n",
    "    if filename.endswith(\".jpg\"):\n",
    "        # read the image\n",
    "        img = cv2.imread(os.path.join(input_dir, filename))\n",
    "        \n",
    "        # perform the cropping operation\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        th, threshed = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
    "        kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n",
    "        morphed = cv2.morphologyEx(threshed, cv2.MORPH_CLOSE, kernel)\n",
    "        cnts = cv2.findContours(morphed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[-2]\n",
    "        cnt = sorted(cnts, key=cv2.contourArea)[-1]\n",
    "        x,y,w,h = cv2.boundingRect(cnt)\n",
    "        dst = img[y:y+h, x:x+w]\n",
    "        \n",
    "        # save the cropped image with the same filename\n",
    "        cv2.imwrite(os.path.join(input_dir, filename), dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15011278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ECG Images of COVID-19 Patients (250)\n",
      "ECG Images of Patient that have History of MI (203)\n",
      "ECG Images of Patient that have abnormal heart beats (548)\n",
      "Normal Person ECG Images (859)\n",
      "ECG Images of Myocardial Infarction Patients (77)\n"
     ]
    }
   ],
   "source": [
    "# define paths\n",
    "source_folder = 'Dataset'\n",
    "destination_folder = 'images'\n",
    "\n",
    "# create destination folder if not exists\n",
    "if not os.path.exists(destination_folder):\n",
    "    os.makedirs(destination_folder)\n",
    "\n",
    "# loop through subdirectories\n",
    "for subdir in os.listdir(source_folder):\n",
    "    subdir_path = os.path.join(source_folder, subdir)\n",
    "    \n",
    "    # check if it is a directory and not a file\n",
    "    if os.path.isdir(subdir_path) and \"ECG\" in subdir_path:\n",
    "        print(subdir)\n",
    "        \n",
    "        # loop through files in subdirectory\n",
    "        for file in os.listdir(subdir_path):\n",
    "            file_path = os.path.join(subdir_path, file)\n",
    "            \n",
    "            # copy file to destination folder\n",
    "            shutil.copy(file_path, destination_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d55447ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Load CSV file containing image filenames and labels\n",
    "df = pd.read_csv('image_labels.csv')\n",
    "df[\"label\"] = df[\"label\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "65926dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "810265fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for train, validation, and test sets\n",
    "train_dir = 'train'\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "\n",
    "test_dir = 'test'\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1ce0f831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move images to respective directories based on the split\n",
    "for i, row in train_df.iterrows():\n",
    "    src = 'images/' + row['filename']\n",
    "    dst = train_dir + '/' + row['filename']\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "for i, row in test_df.iterrows():\n",
    "    src = 'images/' + row['filename']\n",
    "    dst = test_dir + '/' + row['filename']\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d0549517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation for training set\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   rotation_range=20,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True,\n",
    "                                   vertical_flip=True,\n",
    "                                   preprocessing_function=preprocess_input)\n",
    "\n",
    "# No data augmentation for testing set, only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  preprocessing_function=preprocess_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f1aba2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 32\n",
    "\n",
    "# Set target image size\n",
    "target_size = (224, 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5976ffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1541 validated image filenames belonging to 2 classes.\n",
      "Found 386 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Create training and testing generators\n",
    "train_generator = train_datagen.flow_from_dataframe(dataframe=train_df,\n",
    "                                                    directory=train_dir,\n",
    "                                                    x_col='filename',\n",
    "                                                    y_col='label',\n",
    "                                                    target_size=target_size,\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(dataframe=test_df,\n",
    "                                                  directory=test_dir,\n",
    "                                                  x_col='filename',\n",
    "                                                  y_col='label',\n",
    "                                                  target_size=target_size,\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode='binary')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
